<!DOCTYPE html>


<html lang="zh-CN（简体中文） ; en（English） ; zh-TW（繁體中文） ; ja（日本語） ; es（Español） ; de（Deutsch） ; fr（Français） ; ru（Русский） ; ko（한국어） ; vi（Tiếng Việt） ; nl（Nederlands） ; no（norsk） ; pt（Português）">
  

    <head>
      <meta charset="utf-8" />
        
      <meta
        name="viewport"
        content="width=device-width, initial-scale=1, maximum-scale=1"
      />
      <title> My Blog</title>
  <meta name="generator" content="hexo-theme-ayer">
      
      <link rel="shortcut icon" href="/favicon.ico" />
       
<link rel="stylesheet" href="/dist/main.css">

      
<link rel="stylesheet" href="/css/fonts/remixicon.css">

      
<link rel="stylesheet" href="/css/custom.css">
 
      <script src="https://cdn.staticfile.org/pace/1.2.4/pace.min.js"></script>
       
 

      <link
        rel="stylesheet"
        href="https://cdn.jsdelivr.net/npm/@sweetalert2/theme-bulma@5.0.1/bulma.min.css"
      />
      <script src="https://cdn.jsdelivr.net/npm/sweetalert2@11.0.19/dist/sweetalert2.min.js"></script>

      <!-- mermaid -->
      
      <style>
        .swal2-styled.swal2-confirm {
          font-size: 1.6rem;
        }
      </style>
    <!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">
<!-- hexo injector head_end end --><link rel="alternate" href="/atom.xml" title="My Blog" type="application/atom+xml">
</head>
  </html>
</html>


<body>
  <div id="app">
    
      
    <main class="content on">
      
<section class="cover">
    
      
      <a class="forkMe" href="https://github.com/Shen-Yu/hexo-theme-ayer"
        target="_blank"><img width="149" height="149" src="/images/forkme.png"
          class="attachment-full size-full" alt="Fork me on GitHub" data-recalc-dims="1"></a>
    
  <div class="cover-frame">
    <div class="bg-box">
      <img src="/images/cover1.jpg" alt="image frame" />
    </div>
    <div class="cover-inner text-center text-white">
      <h1><a href="/">My Blog</a></h1>
      <div id="subtitle-box">
        
        <span id="subtitle"></span>
        
      </div>
      <div>
        
      </div>
    </div>
  </div>
  <div class="cover-learn-more">
    <a href="javascript:void(0)" class="anchor"><i class="ri-arrow-down-line"></i></a>
  </div>
</section>



<script src="https://cdn.staticfile.org/typed.js/2.0.12/typed.min.js"></script>


<!-- Subtitle -->

  <script>
    try {
      var typed = new Typed("#subtitle", {
        strings: ['休言万事转头空，未转头时皆梦', '愿你一生努力，一生被爱', '想要的都拥有，得不到的都释怀'],
        startDelay: 0,
        typeSpeed: 200,
        loop: true,
        backSpeed: 100,
        showCursor: true
      });
    } catch (err) {
      console.log(err)
    }
  </script>
  
<div id="main">
  <section class="outer">
  
  <ul class="ads">
    
        <li>
            <a target="_blank" rel="noopener" href="https://curl.qcloud.com/kvO7hb43">
                <img src="https://pic.imgdb.cn/item/62174b452ab3f51d912a5ccc.jpg" width="300" alt="云服务器限时秒杀">
            </a>
        </li>
    
        <li>
            <a target="_blank" rel="noopener" href="https://www.vultr.com/?ref=8630075">
                <img src="https://pic.imgdb.cn/item/62174b452ab3f51d912a5cd7.png" width="300" alt="vultr优惠vps">
            </a>
        </li>
    
</ul>
  
  
  

<div class="notice" style="margin-top:50px">
    <i class="ri-heart-fill"></i>
    <div class="notice-content" id="broad"></div>
</div>
<script type="text/javascript">
    fetch('https://v1.hitokoto.cn')
        .then(response => response.json())
        .then(data => {
            document.getElementById("broad").innerHTML = data.hitokoto;
        })
        .catch(console.error)
</script>

<style>
    .notice {
        padding: 20px;
        border: 1px dashed #e6e6e6;
        color: #969696;
        position: relative;
        display: inline-block;
        width: 100%;
        background: #fbfbfb50;
        border-radius: 10px;
    }

    .notice i {
        float: left;
        color: #999;
        font-size: 16px;
        padding-right: 10px;
        vertical-align: middle;
        margin-top: -2px;
    }

    .notice-content {
        display: initial;
        vertical-align: middle;
    }
</style>
  
  <article class="articles">
    
    
    
    
    <article
  id="post-Matlab Cody/Matlab Cody——Basics on Vectors题解"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/07/22/Matlab%20Cody/Matlab%20Cody%E2%80%94%E2%80%94Basics%20on%20Vectors%E9%A2%98%E8%A7%A3/"
    >Matlab Cody——Basics on Vectors题解</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/07/22/Matlab%20Cody/Matlab%20Cody%E2%80%94%E2%80%94Basics%20on%20Vectors%E9%A2%98%E8%A7%A3/" class="article-date">
  <time datetime="2023-07-22T03:27:48.000Z" itemprop="datePublished">2023-07-22</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="0-Matlab-Cody-简介"><a href="#0-Matlab-Cody-简介" class="headerlink" title="0. Matlab Cody 简介"></a>0. Matlab Cody 简介</h2><p>Matlab Cody是一个类似Leetcode的oj网站，网址：<a target="_blank" rel="noopener" href="https://ww2.mathworks.cn/matlabcentral/cody">https://ww2.mathworks.cn/matlabcentral/cody</a></p>
<h2 id="1-Problem-3-Find-the-sum-of-all-the-numbers-of-the-input-vector"><a href="#1-Problem-3-Find-the-sum-of-all-the-numbers-of-the-input-vector" class="headerlink" title="1. Problem 3. Find the sum of all the numbers of the input vector"></a>1. Problem 3. Find the sum of all the numbers of the input vector</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">vecsum</span><span class="params">(x)</span></span></span><br><span class="line">   y = sum(x,<span class="string">&#x27;all&#x27;</span>)</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="2-Problem-6-Select-every-other-element-of-a-vector"><a href="#2-Problem-6-Select-every-other-element-of-a-vector" class="headerlink" title="2. Problem 6. Select every other element of a vector"></a>2. Problem 6. Select every other element of a vector</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">everyOther</span><span class="params">(x)</span></span></span><br><span class="line">  y = x(<span class="number">1</span>:<span class="number">2</span>:<span class="keyword">end</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="3-Problem-247-Arrange-Vector-in-descending-order"><a href="#3-Problem-247-Arrange-Vector-in-descending-order" class="headerlink" title="3. Problem 247. Arrange Vector in descending order"></a>3. Problem 247. Arrange Vector in descending order</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">desSort</span><span class="params">(x)</span></span></span><br><span class="line">  y = <span class="built_in">sort</span>(x,<span class="string">&#x27;descend&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="4-Problem-135-Inner-product-of-two-vectors"><a href="#4-Problem-135-Inner-product-of-two-vectors" class="headerlink" title="4. Problem 135. Inner product of two vectors"></a>4. Problem 135. Inner product of two vectors</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">z</span> = <span class="title">your_fcn_name</span><span class="params">(x,y)</span></span></span><br><span class="line">  z = <span class="built_in">dot</span>(x,y);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="5-Problem-624-Get-the-length-of-a-given-vector"><a href="#5-Problem-624-Get-the-length-of-a-given-vector" class="headerlink" title="5. Problem 624. Get the length of a given vector"></a>5. Problem 624. Get the length of a given vector</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">VectorLength</span><span class="params">(x)</span></span></span><br><span class="line">  y = <span class="built_in">length</span>(x);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="6-Problem-1107-Find-max"><a href="#6-Problem-1107-Find-max" class="headerlink" title="6. Problem 1107. Find max"></a>6. Problem 1107. Find max</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">your_fcn_name</span><span class="params">(x)</span></span></span><br><span class="line">  y = <span class="built_in">max</span>(x,[],<span class="string">&#x27;all&#x27;</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="7-Problem-605-Whether-the-input-is-vector"><a href="#7-Problem-605-Whether-the-input-is-vector" class="headerlink" title="7. Problem 605. Whether the input is vector?"></a>7. Problem 605. Whether the input is vector?</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">checkvector</span><span class="params">(x)</span></span></span><br><span class="line">  <span class="keyword">if</span> <span class="built_in">isvector</span>(x)</span><br><span class="line">      y = <span class="number">1</span>;</span><br><span class="line">  <span class="keyword">else</span></span><br><span class="line">      y = <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="8-Problem-2631-Flip-the-vector-from-right-to-left"><a href="#8-Problem-2631-Flip-the-vector-from-right-to-left" class="headerlink" title="8. Problem 2631. Flip the vector from right to left"></a>8. Problem 2631. Flip the vector from right to left</h2><p>题目要求不能直接使用函数，所以自己写<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">flip_vector</span><span class="params">(x)</span></span></span><br><span class="line">  y = x(<span class="keyword">end</span>:<span class="number">-1</span>:<span class="number">1</span>);</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure></p>
<h2 id="9-Problem-3076-Create-a-vector"><a href="#9-Problem-3076-Create-a-vector" class="headerlink" title="9. Problem 3076. Create a vector"></a>9. Problem 3076. Create a vector</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">zeroToNby2</span><span class="params">(n)</span></span></span><br><span class="line">  y = <span class="number">0</span>:<span class="number">2</span>:n;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="10-Problem-1024-Doubling-elements-in-a-vector"><a href="#10-Problem-1024-Doubling-elements-in-a-vector" class="headerlink" title="10. Problem 1024. Doubling elements in a vector"></a>10. Problem 1024. Doubling elements in a vector</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">B</span> = <span class="title">your_fcn_name</span><span class="params">(A)</span></span></span><br><span class="line">  B = <span class="built_in">zeros</span>(<span class="number">1</span>,<span class="number">2</span>*<span class="built_in">length</span>(A));</span><br><span class="line">  B(<span class="number">1</span>:<span class="number">2</span>:<span class="keyword">end</span><span class="number">-1</span>) = A;</span><br><span class="line">  B(<span class="number">2</span>:<span class="number">2</span>:<span class="keyword">end</span>) = A;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure>
<h2 id="11-Problem-42651-Vector-creation"><a href="#11-Problem-42651-Vector-creation" class="headerlink" title="11. Problem 42651. Vector creation"></a>11. Problem 42651. Vector creation</h2><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">function</span> <span class="title">y</span> = <span class="title">vector</span><span class="params">(x)</span></span></span><br><span class="line">  y = <span class="number">1</span>:x;</span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E4%BB%A3%E7%A0%81%E6%89%93%E5%8D%A1/" rel="tag">代码打卡</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-遥感基础/辐射基础/辐射基础1"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/05/21/%E9%81%A5%E6%84%9F%E5%9F%BA%E7%A1%80/%E8%BE%90%E5%B0%84%E5%9F%BA%E7%A1%80/%E8%BE%90%E5%B0%84%E5%9F%BA%E7%A1%801/"
    >辐射基础1</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/05/21/%E9%81%A5%E6%84%9F%E5%9F%BA%E7%A1%80/%E8%BE%90%E5%B0%84%E5%9F%BA%E7%A1%80/%E8%BE%90%E5%B0%84%E5%9F%BA%E7%A1%801/" class="article-date">
  <time datetime="2023-05-21T14:01:08.000Z" itemprop="datePublished">2023-05-21</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
   
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E9%81%A5%E6%84%9F%E5%9F%BA%E7%A1%80/" rel="tag">遥感基础</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-统计学习方法/林轩田机器学习每章要点"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/05/14/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%AF%8F%E7%AB%A0%E8%A6%81%E7%82%B9/"
    >林轩田机器学习每章要点</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/05/14/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/%E6%9E%97%E8%BD%A9%E7%94%B0%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%AF%8F%E7%AB%A0%E8%A6%81%E7%82%B9/" class="article-date">
  <time datetime="2023-05-14T15:33:59.000Z" itemprop="datePublished">2023-05-14</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="0-符号假设"><a href="#0-符号假设" class="headerlink" title="0. 符号假设"></a>0. 符号假设</h1><h1 id="1-When-Can-Machine-Learn"><a href="#1-When-Can-Machine-Learn" class="headerlink" title="1. When Can Machine Learn?"></a>1. When Can Machine Learn?</h1><h2 id="1-1"><a href="#1-1" class="headerlink" title="1.1"></a>1.1</h2><h2 id="1-2-Learning-to-Answer-Yes-­No"><a href="#1-2-Learning-to-Answer-Yes-­No" class="headerlink" title="1.2 Learning to Answer Yes-­No"></a>1.2 Learning to Answer Yes-­No</h2><p>本节主要介绍了感知机算法，它在一定条件下可以使得 $\textbf{E}_{in} \approx 0$ (在数据集上的误差近似为0)。</p>
<p>感知机学习算法 $\mathcal{A}$ 通过线性可分的数据 $\mathcal{D}$ 以及感知机 $\mathcal{H}$ 获得假设 $g$ </p>
<ul>
<li>感知机的假设空间：定义在 $\mathbb{R}^d$ 上的一条直线或超平面</li>
<li>感知机算法可以不断纠正错误并改进</li>
<li>感知机的分类正确性保证：数据是线性可分的</li>
<li>无法分类的数据：存储效果最好的直线</li>
</ul>
<h2 id="1-3-Types-of-Learning"><a href="#1-3-Types-of-Learning" class="headerlink" title="1.3 Types of Learning"></a>1.3 Types of Learning</h2><p>本节主要介绍机器学习的分类</p>
<ul>
<li>按输出空间 $\mathcal{Y}$ 分类：分类、回归、结构化学习</li>
<li>按数据标签 $y_n$ 分类：监督学习、半监督学习、无监督学习、强化学习</li>
<li>按不同的学习方式分类：批量学习、在线学习、主动学习</li>
<li>按输入空间 $\mathcal{X}$ 分类：具体意义的数据、原始数据、抽象数据</li>
</ul>
<h2 id="1-4-Feasibility-of-Learning"><a href="#1-4-Feasibility-of-Learning" class="headerlink" title="1.4 Feasibility of Learning"></a>1.4 Feasibility of Learning</h2><p>本节主要介绍机器学习的可能性 </p>
<ul>
<li>NFL定理：面对所有的问题，没有一种算法能说比另一种算法更好</li>
<li><p>验证一个固定假设 $h$ 的 $E_{in}$ 和 $E_{out}$ 是否PAC</p>
<ul>
<li><p>机器能够学习的必要条件：样本满足独立同分布假设 (每次抽样之间相互独立，样本服从同一分布)</p>
</li>
<li><p>$E_{in}$ 为抽样样本（数据集）内所有数据中 $h(\vec{x}) = f(\vec{x})$ 的概率，<br>$E_{out}$ 为抽样样本外所有数据中 $h(\vec{x}) = f(\vec{x})$ 的概率</p>
<p> ($E_{in}(h) = \frac{1}{N} \sum\limits_{n=1}^{N} \mathbb{I}[h(\vec{x}) \neq y_n]$、<br> $E_{out} = \mathop{\varepsilon}\limits_{\vec{x} \sim{P}} \mathbb{I}[h(\vec{x}) \neq f(\vec{x})]$)</p>
</li>
<li><p>Hoeffding 不等式：$P[\lvert E_{in} - E_{out} \rvert &gt; \epsilon] \leq 2exp(-2 \epsilon^2 N)$</p>
<p> (说明了只要样本数 $N$ 够大，$E_{in}$ 和 $E_{out}$ 相差的很大概率会很小，也就可以用 $E_{in}$ 来估计 $E_{out}$)</p>
</li>
<li>上述 Hoeffding 不等式说明了 $E_{in}$ 和 $E_{out}$ 是 PAC(概率近似相等) 的</li>
</ul>
</li>
<li><p>在 $E_{in}(h)$ 足够小且 $\lvert \mathcal{H} \rvert$ 有限的情况下，学习有可能能实现了</p>
<ul>
<li>坏数据集 (BAD $\mathcal{D}$)：使得假设 $h$ 的 $E_{in}$ 和 $E_{out}$ 相差很大的数据集</li>
<li><p>$P_{\mathcal{D}}(BAD \; \mathcal{D}) \leq P(BAD \; \mathcal{D} \; for \; h_1) + … + P(BAD \; \mathcal{D} \; for \; h_M)$</p>
<p> $P_{\mathcal{D}}(BAD \; \mathcal{D}) \leq 2exp(-2 \epsilon^2 N) + … + 2exp(-2 \epsilon^2 N)$</p>
<p> $P_{\mathcal{D}}(BAD \; \mathcal{D}) \leq 2Mexp(-2 \epsilon^2 N)$ </p>
<p> 也就是说只要 $N$ 足够大，$\lvert \mathcal{H} \rvert$ 有限的情况下。<br> 不管使用什么算法 $\mathcal{A}$ 都能够使得 $E_{in}$ 和 $E_{out}$ PAC，</p>
<p> 如果 $\mathcal{A}$ 可以找到 $g$ 使 $E_{in}(g) \approx 0$ 那么PAC可以保证 $E_{out}(g) \approx 0$</p>
</li>
</ul>
</li>
</ul>
<h1 id="2-Why-Can-Machines-Learn"><a href="#2-Why-Can-Machines-Learn" class="headerlink" title="2. Why Can Machines Learn?"></a>2. Why Can Machines Learn?</h1><h2 id="2-1-Training-VS-Testing"><a href="#2-1-Training-VS-Testing" class="headerlink" title="2.1 Training VS Testing"></a>2.1 Training VS Testing</h2><p>本节主要介绍假设数量 $M = \infty$ 时，机器学习是否有可能性</p>
<ul>
<li>$M$ 过小 $E_{in}(g) \approx 0$ 难以实现(选择过少)，$M$ 过大出现坏样本的概率又显著增加，<br>导致 $E_{in}(g)$ 和 $E_{out}(g)$ 无法PAC</li>
<li>按照对数据集中样本点的分类结果可以将无穷种假设分成 $effective(N)$ 种，<br>如果 $effective(N) &lt;&lt; 2^N$ ，机器学习是有可能的</li>
<li>成长函数 $m_{\mathcal{H}}(N)$ 是含N个数据点的数据集最多的假设种类数<br>($m_{\mathcal{H}}(N) = \mathop{max}\limits_{\vec{x_1},…,\vec{x_N} \in \mathcal{X}} \lvert \mathcal{H}(x_1,…,x_N) \rvert$)</li>
<li>$m_{\mathcal{H}}(N) = O(N^{k-1})$ ($k$ 是break point，也就是 $k$ 个样本点类别的 $2^k$ 种情况<br>都能被 $\mathcal{H}$ 中其中一个假设全部正确分类)   </li>
</ul>
<h2 id="2-2-Theory-of-Generalization"><a href="#2-2-Theory-of-Generalization" class="headerlink" title="2.2 Theory of Generalization"></a>2.2 Theory of Generalization</h2><ul>
<li>$N &gt; k$ 时，$m_{\mathcal{H}}(N)$ 会比 $2^N$ 小的多</li>
<li><p>Bounding Function $B(N,k)$ 是 $m_{\mathcal{H}}(N)$ 的上限，以下是它的一些性质:</p>
<ul>
<li><p>$k = 1$ 时，$B(N,1) = 1$</p>
</li>
<li><p>$N &lt; k$ 时，$B(N,k) = 2^N$ (相当于没有限制)</p>
</li>
<li><p>$N = k$ 时，$B(N,k) = 2^k - 1$ (刚出现不能被覆盖的分类情况)</p>
</li>
</ul>
</li>
<li><p>通过递推得到 $B(N,k)$ 其他情况下的一些性质:</p>
<ul>
<li><p>把 $N$ 个样本可以被覆盖的二分情况再分为两类：第一类每两种情况的 $x_1$ 到 $x_{k-1}$ 的类别完全相同，$x_k$ 的类别不同且成对，其他为第二类</p>
</li>
<li><p>第一类情况个数记为 $\alpha$，第二类为 $\beta$，存在以下关系：$B(N,k) = 2\alpha + \beta$、<br>$\alpha + \beta \leq B(N-1,k)$、$\alpha \leq B(N-1,k-1)$</p>
</li>
<li><p>因此可以得到 $B(N,k) = B(N-1,k) + B(N-1,k-1)$ (取等证明略)</p>
</li>
<li><p>因此 $B(N,k) = \sum\limits_{i=0}^{k-1} C_i^N$，最高次项为 $N^{k-1}$，所以成长函数 $m_{\mathcal{H}}(N)$ 是 $poly(N)$ 的</p>
</li>
</ul>
</li>
<li><p>用成长函数 $m_{\mathcal{H}}(N)$ 替代 $M$ 证明 $E_{in}$ 和 $E_{out}$ 是PAC的</p>
<ul>
<li><p>证明略</p>
</li>
<li><p>VC bound：$P_{\mathcal{D}}(\lvert E_{in} - E_{out} \rvert &gt; \epsilon) \leq 4m_{\mathcal{H}}(N)exp(-\frac{1}{8} \epsilon^2 N)$</p>
</li>
</ul>
</li>
</ul>
<h2 id="2-3-The-VC-Dimension"><a href="#2-3-The-VC-Dimension" class="headerlink" title="2.3 The VC Dimension"></a>2.3 The VC Dimension</h2><p>本节介绍VC维的意义及其与泛化能力的关系</p>
<ul>
<li><p>VC维的定义：使得 $m_{\mathcal{H}}(N) = 2^N$ 成立的最大N，记为 $d_{VC}$</p>
<ul>
<li><p>机器学习的条件：1、$m_{\mathcal{H}}(N)$ 有间断点k；2、样本数N足够大(这两点保证 $E_{out}$ 和 $E_{in}$ PAC)；<br>3、合适的算法 $\mathcal{A}$ (保证 $E_{in} \approx 0$)</p>
</li>
<li><p>$d_{VC}$ 有限时，$E_{out}$ 和 $E_{in}$ 是PAC的</p>
</li>
</ul>
</li>
<li><p>$d_{VC} = d+1$ </p>
<ul>
<li><p>先证明 $d_{VC} \geq d+1$，由于 $X\vec{w}_{d+1} = \vec{y}_{d+1}$ 可得 $\vec{w} = X^{-1}\vec{y}$<br> (X有 $d+1$ 个维度和 $d+1$ 个样本).</p>
<p> 因此对每一种 $\vec{y}$，$\vec{w}$ 唯一确定. $\vec{w}$ 的所有情况也就可以覆盖 $\vec{y}$ 的所有情况</p>
</li>
<li><p>再证明 $d_{VC} \leq d+1$，也就是对 $d+2$ 个样本 $\vec{w}$ 的所有情况不可以覆盖 $\vec{y}$ 的所有情况</p>
<p> 由于 $\vec{x}_{d+2}$ (第 $d+2$ 个样本) 能被表示成前 $d+1$ 个样本的线性组合. </p>
<p> 也就是：$\vec{x}_{d+2} = a_1\vec{x}_{1} + … + a_{d+1}\vec{x}_{d+1}$ </p>
<p> 因此存在 $\vec{w}$ 使得 $\vec{x}_{d+2}<em>\vec{w} = a_1\vec{x}_{1}</em>\vec{w} + … + a_{d+1}\vec{x}_{d+1}*\vec{w}&gt;0$</p>
<p> 这种情况下 $\vec{x}_{d+2}$ 一定是正类. $\vec{w}$ 的所有情况不能覆盖 $\vec{y}$ 的所有情况</p>
</li>
</ul>
</li>
<li>$d_{VC}$ 的物理意义：假设空间的自由度。所以 $M$ 和 $d_{VC}$ 是成正比的</li>
<li><p>$d_{VC}$ 和泛化能力、样本复杂度以及模型复杂度的关系</p>
<ul>
<li><p>$E_{out}(g) \leq E_{in}(g) + \sqrt{\dfrac{8}{N} \ln{\dfrac{4(2N)^{d_{VC}}}{\delta}}}$</p>
</li>
<li><p>$\Omega(N,\mathcal{H},\delta) = \sqrt{\dfrac{8}{N} \ln{\dfrac{4(2N)^{d_{VC}}}{\delta}}}$ 称为模型复杂度的惩罚项</p>
</li>
<li><p>随着 $d_{VC}$ 增加，$E_{in}$ 下降，但是 $\Omega$ 上升。所以 $E_{out}$ 随 $d_{VC}$ 先下降后上升</p>
</li>
<li><p>样本复杂度：$d_{VC}$ 固定的情况下，$N$ 的合理取值(理论上 $N \approx 10000d_{VC}$ 实际上只需要 $N \approx 10d_{VC}$)</p>
</li>
</ul>
</li>
</ul>
<h2 id="2-4-Noise-and-Error"><a href="#2-4-Noise-and-Error" class="headerlink" title="2.4  Noise and Error"></a>2.4  Noise and Error</h2><p>本节主要说了在数据集有噪声的情况下，VC维依然是成立的，机器学习依然是可能的</p>
<ul>
<li>样本由 $P(y|\vec{x})$ (也就是 $f(\vec{x}) + noise$ ) 产生<ul>
<li>只要 $\vec{x} \stackrel{\text{i.i.d}}{\sim}{P(\vec{x})}$ 和 $y \stackrel{\text{i.i.d}}{\sim}{P(y)}$，VC维理论依然成立</li>
</ul>
</li>
<li><p>误差的度量方式</p>
<ul>
<li><p>误差度量的特点：1、只考虑样本外的未知数据，2、分别考虑每个数据点的误差(不一定满足，但本课程只考虑这个)</p>
</li>
<li><p>常用误差有：0-1误差和平均平方误差(MSE)，前者用于分类，后者用于回归</p>
</li>
<li><p>0-1误差下的 $f(\vec{x}) = \mathop{\arg\max}\limits_{y \in \mathcal{Y}} P(y|\vec{x})$，使得翻转噪声最小</p>
</li>
<li><p>MSE下的 $f(\vec{x}) = \sum\limits_{y \in \mathcal{Y}} yP(y|\vec{x})$，使得高斯噪声最小</p>
</li>
</ul>
</li>
<li>错误衡量设计的两种方式：有意义的或者易于设计算法</li>
<li>通过”虚拟复制”某类错误对应的标签的样本w次的方法，可以计算 $E_{in}^w$ (w为某类错误的权重)</li>
</ul>
<h1 id="3-How-Can-Machines-Learn"><a href="#3-How-Can-Machines-Learn" class="headerlink" title="3. How Can Machines Learn?"></a>3. How Can Machines Learn?</h1><h2 id="3-1-Linear-Regression"><a href="#3-1-Linear-Regression" class="headerlink" title="3.1 Linear Regression"></a>3.1 Linear Regression</h2><ul>
<li>线性回归使用超平面 $h(\vec{x}) = \vec{w}^T\vec{x}$ 估计真实值</li>
<li><p>线性回归存在用伪逆表示的解析解 $\vec{w}_{LIN} = X^{\dagger}\vec{y}$</p>
<ul>
<li><p>MSE误差最小等价于：$\min\limits_{\vec{w}} E_{in}(\vec{w}) = \frac{1}{N} \Vert X\vec{w} - \vec{y} \Vert^2$</p>
</li>
<li><p>因为MSE损失函数为凸函数，所以 $\nabla E_{in}(\vec{w}) = 0$ 处即为最小值点</p>
</li>
</ul>
</li>
<li><p>线性回归相当于使 $\vec{y}$ 投影到由 $X$ 的特征张成的平面内，其中 $y - \hat{y}$ 是误差</p>
<ul>
<li><p>$trace(I - H) = N-(d+1)$ 表示$\vec{y}$ 投影到由 $X$ 的特征张成的平面内损失的自由度</p>
</li>
<li><p>如果有真实值来自于$f(X) \in span{X}$，那么对 <strong>noise</strong> 进行投影即 $I-H$ 操作可得：</p>
<p>  $\overline{E_{in}} = \frac{1}{N}\Vert y - \hat{y} \Vert^2 = \frac{1}{N}\Vert (I-H)\textbf{noise} \Vert^2 =<br>  \textbf{noise} (1-\frac{d+1}{N})$</p>
</li>
<li><p>$\overline{E_{out}} = \textbf{noise} (1+\frac{d+1}{N})$，随着 $N$ 逐渐增大 $\overline{E_{in}} \approx \overline{E_{out}}$</p>
</li>
</ul>
</li>
<li>用回归器进行分类的代价是更松的上界，因为 $err_{0/1} \leq err_{sqr}$，所以 $E_{out} \leq 分类E_{in} + 复杂度 \leq 回归E_{in} + 复杂度$</li>
</ul>
<h2 id="3-2-Logistic-Regression"><a href="#3-2-Logistic-Regression" class="headerlink" title="3.2  Logistic Regression"></a>3.2  Logistic Regression</h2><ul>
<li>Logistic 回归的目标函数是 $P(+1|x)$，其假设为 $h(x) = \theta(\vec{w}^T x)$(其中 $\theta = \dfrac{1}{1+e^{-s}}$)</li>
<li>Logistic 回归的损失函数是交叉熵函数(似然函数的负对数 $L(\vec{w}) = \frac{1}{N}\sum\limits_{n=1}^{N} -\ln \theta(y_n \vec{w}^T \vec{x}_n)$)</li>
<li>Logistic 回归的损失函数是凸函数，因此其最小值在<br>$\nabla E_{in}(\vec{w}) = \frac{1}{N} \sum\limits_{n=1}^{N} \theta(-y_n \vec{w}^T \vec{x}_n) (-y_n \vec{x}_n) = 0$ 处取得</li>
<li>Logistic 回归可以用梯度下降法求得 $L(\vec{w})$ 最小值<ul>
<li>$\vec{w}$ 更新方式：$\vec{w}_{t+1} = \vec{w}_{t} + \eta \vec{v}$</li>
<li>$\eta$ 很小的时候可以泰勒展开近似，$E_{in}(\vec{w}_{t+1}) \approx E_{in}(\vec{w}_{t} + \eta \vec{v}^T \nabla E_{in}(\vec{w}_t))$</li>
<li>当 $\vec{v}$ 与 $\nabla E_{in}(\vec{w}_t)$ 方向相反时(即 $\vec{v} = -\dfrac{\nabla E_{in}(\vec{w}_t)}{\Vert \nabla E_{in}(\vec{w}_t) \Vert}$)<br>$E_{in}$ 下降最快</li>
<li>我们希望 $\eta$ 与 $\Vert \nabla E_{in}(\vec{w}_t) \Vert$ 正相关，因此更新的式子可以改为:<br>$\vec{w}_{t+1} = \vec{w}_{t} - \eta \nabla E_{in}(\vec{w}_t)$</li>
</ul>
</li>
</ul>
<h2 id="3-3-Linear-Models-for-Classification"><a href="#3-3-Linear-Models-for-Classification" class="headerlink" title="3.3 Linear Models for Classification"></a>3.3 Linear Models for Classification</h2><ul>
<li>线性回归和Logistic 回归都可以解决线性分类问题</li>
<li>随机梯度下降(SGD)可以简化更新操作到 $\mathcal{O}(1)$ 复杂度<br>简化后的更新操作：$\vec{w}_{t+1} = \vec{w}_{t} - \eta \theta(-y_n \vec{w}_t^T \vec{x}_n) (-y_n \vec{x}_n)$</li>
<li>多分类问题<ul>
<li>OVA：对每一类和所有其他类别数据做二分类，分别计算 $P(k|\vec{x})$<ul>
<li>优点：高效，可以和所有类似Logistic 回归的算法结合</li>
<li>缺点：K较大时容易类别不平衡</li>
</ul>
</li>
<li>OVO：对每一类和每种其他类别数据做二分类<ul>
<li>优点：可以和所有二分类算法结合</li>
<li>缺点：时空复杂度高，预测速度慢</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="3-4-Nonlinear-Transformation"><a href="#3-4-Nonlinear-Transformation" class="headerlink" title="3.4 Nonlinear Transformation"></a>3.4 Nonlinear Transformation</h2><ul>
<li>可以用一非线性函数 $\Phi$ 将非线性函数映射到线性空间中，实现x域到z域特征转换</li>
<li>z域特征维度 $\tilde{d} = C_{Q+d}^{Q} = C_{Q+d}^{d} = \mathcal{O}(Q^d)$ 较大，<br>会导致模型泛化能力差，时空复杂度高</li>
<li>优先选择 $Q$ 较小的假设，如果 $E_{in}$ 太高在考虑复杂假设</li>
</ul>
<h1 id="4-How-Can-Machines-Learn-Better"><a href="#4-How-Can-Machines-Learn-Better" class="headerlink" title="4. How Can Machines Learn Better?"></a>4. How Can Machines Learn Better?</h1><h2 id="4-1-Hazard-of-Overfitting"><a href="#4-1-Hazard-of-Overfitting" class="headerlink" title="4.1  Hazard of Overfitting"></a>4.1  Hazard of Overfitting</h2><ul>
<li>过拟合：$E_{in}$ 变小但是 $E_{out}$ 变大的过程。以下是过拟合常见原因：<ul>
<li>VC Dimension太大</li>
<li>随机噪声或系统性噪声过强</li>
<li>训练样本数 $N$ 不够</li>
</ul>
</li>
<li>避免过拟合的措施:<ul>
<li>从简单的模型开始</li>
<li>数据清理(修正明显错误的label或者删除错误样本点)</li>
<li>数据增强(注意新增的数据可能和原来数据不是 $i.i.d.$ 的，尽量保证新数据内的样本是 $i.i.d.$ 的)</li>
<li>正则化</li>
<li>验证</li>
</ul>
</li>
</ul>
<h2 id="4-2-Regularization"><a href="#4-2-Regularization" class="headerlink" title="4.2 Regularization"></a>4.2 Regularization</h2><ul>
<li>正则化约束条件：$\Vert \vec{w} \Vert^2 \leq C$，$H_n \subset H(C) \subset H_m$ ($n&lt;m$)</li>
<li>最优解需要满足 $-\nabla E_{in}(w_{reg})$ 与 $w^Tw = C$ 的法向量平行，<br>即 $\nabla E_{in}(w_{reg}) + \frac{2\lambda}{N}w_{reg}=0$<ul>
<li>求解 $w_{reg}$ 等价于最小化 $E_{aug} = E_{in} + \frac{\lambda}{N} w_{reg}^Tw_{reg}$</li>
<li>多项式变换除了可以用朴素的 $x^n$，也可以用勒让德多项式</li>
</ul>
</li>
<li>$E_{aug}$ 可以看成 $E_{out}$ 的代理<ul>
<li>$E_{aug} = E_{in} + \frac{\lambda}{N} w^Tw$ 中的 $w^Tw$ 是单个假设的复杂度，记为 $\Omega(w)$。<br>整个 $H$ 的复杂度为 $\Omega(H)$，$\Omega(w)$ 包含在 $\Omega(H)$ 中</li>
<li>整个 $H$ 的VC维是 $d_{VC} = \tilde{d} + 1$，引入正则化限定条件 $H(C)$ 后的VC维记为 $d_{EFF}(H,A)$.<br>则有 $d_{EFF}(H,A) \leq d_{VC}$</li>
</ul>
</li>
<li>正则化项选择方法<ul>
<li>基于目标特性，比如目标具有对称性则考虑用 $\sum\mathbb{I}(q \% 2==0)w^2_q$ 作为正则化项</li>
<li>接近真实(曲线平滑、简单)，如L1正则化 $\sum \vert w_q \vert$</li>
<li>易于实现，如L2正则化 $\sum w^2_q$</li>
<li>噪音越大，$\lambda$ 也要越大</li>
</ul>
</li>
</ul>
<h2 id="4-3-Validation"><a href="#4-3-Validation" class="headerlink" title="4.3 Validation"></a>4.3 Validation</h2><p>模型选择指的是在 $M$ 个假设空间 $H_m$ 对应 $M$ 种算法 $A_m$ 中选择最优假设空间 $H_{m^*}$ </p>
<p>使得 $g_{m^<em>} = A_{m^</em>}(D)$，$E_{out}(g_{m^*})$ 最小</p>
<ul>
<li>用验证集选择模型<ul>
<li>用 $E_{in}$ 选择模型是危险的(因为即用 $D$ 训练模型又用它选择模型)</li>
<li>用 $E_{test}$ 选择模型是作弊且无法实现的(难以获得测试数据)</li>
</ul>
</li>
<li>验证集模型选择原理：$E_{out}(g) \mathop{\approx}\limits_{small K} E_{out}(g^-) \mathop{\approx}\limits_{large K} E_{val}(g^-)$<ul>
<li>验证集大小 $K$ 越大，$g^-$ 越不如 $g$，但是 $E_{val}$ 越接近 $E_{out}$ (学习曲线)</li>
<li>验证集大小 $K$ 越小，$g^-$ 越接近 $g$，但是 $E_{val}$ 越不如 $E_{out}$ (学习曲线)</li>
</ul>
</li>
<li>留一法交叉验证(LOOCV) 的期望 $\mathop{\varepsilon}\limits_{D} E_{LOOCV}(H,A) = \overline{E_{out}}(N-1)$<br>是对 $\overline{E_{out}}$的近似无偏估计<ul>
<li>$E_{LOOCV} = \frac{1}{N} \sum\limits_{n=1}^{N} err(g_m^-(\vec{x}_n),y_n)$ ($K = 1$ 的特殊情况)</li>
<li>LOOCV的缺点：计算量大、结果不稳定</li>
</ul>
</li>
<li>V折交叉验证公式：$E_{CV} = \frac{1}{V} \sum\limits_{v=1}^{V} E_{val}^{(v)}(g_v^-)$</li>
</ul>
<h2 id="4-4-Three-Learning-Principles"><a href="#4-4-Three-Learning-Principles" class="headerlink" title="4.4 Three Learning Principles"></a>4.4 Three Learning Principles</h2><ul>
<li>奥卡姆剃刀原则：适合数据的最简单的模型是最合适的</li>
<li>抽样误差：数据要匹配测试环境</li>
<li>偷窥数据：容易造成过拟合。应当避免通过数据进行决策，并且对别人的研究成果保持警惕</li>
<li>power of three<ul>
<li>机器学习相关的三个领域：数据挖掘、机器学习、统计</li>
<li>三个理论保证：霍夫丁不等式、多假设霍夫丁不等式、VC维</li>
<li>三种线性模型：感知机、线性回归、Logistic回归</li>
<li>三种重要的工具：特征转换、正则化、验证</li>
<li>三个锦囊妙计：奥卡姆剃刀、防止抽样误差、谨慎偷窥数据</li>
<li>机器学习未来方向：更多转换、更多正则化、更少标签</li>
</ul>
</li>
</ul>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-统计学习方法/chap4 朴素贝叶斯模型简洁总结"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/05/13/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/chap4%20%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B%E7%AE%80%E6%B4%81%E6%80%BB%E7%BB%93/"
    >chap4 朴素贝叶斯模型简洁总结</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/05/13/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/chap4%20%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E6%A8%A1%E5%9E%8B%E7%AE%80%E6%B4%81%E6%80%BB%E7%BB%93/" class="article-date">
  <time datetime="2023-05-13T05:31:49.000Z" itemprop="datePublished">2023-05-13</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
   
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-统计学习方法/chap3 KNN模型简洁总结"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/05/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/chap3%20KNN%E6%A8%A1%E5%9E%8B%E7%AE%80%E6%B4%81%E6%80%BB%E7%BB%93/"
    >chap3 KNN模型简洁总结</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/05/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/chap3%20KNN%E6%A8%A1%E5%9E%8B%E7%AE%80%E6%B4%81%E6%80%BB%E7%BB%93/" class="article-date">
  <time datetime="2023-05-12T15:23:56.000Z" itemprop="datePublished">2023-05-12</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>由于KNN是一种基于实例学习的算法，不需要训练过程。</p>
<p>只需要确定了数据集、距离度量、k值以及分类规则，某个样本的类别就能被唯一确定。</p>
<p>因此下文不介绍学习策略和学习算法。</p>
<h2 id="1、KNN模型"><a href="#1、KNN模型" class="headerlink" title="1、KNN模型"></a>1、KNN模型</h2><p>输入空间：$\mathcal{X} \in \mathbb{R}^n$ </p>
<p>输出空间：$\mathcal{y} \in \{c_1,c_2,…,c_K\}$</p>
<p>特征空间：不显式学习</p>
<h2 id="2、距离度量"><a href="#2、距离度量" class="headerlink" title="2、距离度量"></a>2、距离度量</h2><p>一般采用 $L_p$ 距离(闵可夫斯基距离，Minkowski distance). </p>
<p>$L_p$ 的表达式：$L_p(\vec{x_i},\vec{x_j}) = (\sum\limits_{l=1}^n \lvert x_i^{(l)} - x_j^{(l)} \rvert ^p)^{\frac{1}{p}}$ $\quad$ ($p \geq 1$)</p>
<p>$p = 2$ 时就是欧氏距离：$L_2(\vec{x_i},\vec{x_j}) = \sqrt{\sum\limits_{l=1}^n (x_i^{(l)} - x_j^{(l)})^2}$</p>
<p>$p = 1$ 时称为曼哈顿距离：$L_1(\vec{x_i},\vec{x_j}) =  \sum\limits_{l=1}^n \lvert x_i^{(l)} - x_j^{(l)} \rvert$</p>
<p>$p = \infty$ 时，它是各个维度坐标距离的最大值：$L_{\infty} = \max\limits_{l} \lvert x_i^{(l)} - x_j^{(l)} \rvert$</p>
<h2 id="3、k值选择"><a href="#3、k值选择" class="headerlink" title="3、k值选择"></a>3、k值选择</h2><p>k值过小，模型容易受到噪声点影响导致过拟合；k值过大则容易欠拟合. </p>
<p>k值一般通过交叉验证选取。</p>
<h2 id="4、分类决策规则"><a href="#4、分类决策规则" class="headerlink" title="4、分类决策规则"></a>4、分类决策规则</h2><p>一般考虑让经验风险最小，也就是误分类率 $\frac{1}{K} \sum\limits_{\vec{x_i} \in N_K(\vec{x})} \mathbb{I}(y_i \neq c_k)$ 最小</p>
<p>也就是要让 $\frac{1}{K} \sum\limits_{\vec{x_i} \in N_K(\vec{x})}\mathbb{I}(y_i = c_j) = 1 - \frac{1}{K} \sum\limits_{\vec{x_i} \in N_K(\vec{x})} \mathbb{I}(y_i \neq c_k)$ 最大</p>
<p>当损失函数为0-1损失很熟时，多数表决规则分类函数为：$y = \mathop{\arg\max}\limits_{c_j} \sum\limits_{\vec{x_i} \in N_K(\vec{x})}\mathbb{I}(y_i = c_j)$</p>
<p>所以多数表决规则等价于经验风险最小</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-统计学习方法/chap2 感知机模型简洁总结"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/05/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/chap2%20%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%A8%A1%E5%9E%8B%E7%AE%80%E6%B4%81%E6%80%BB%E7%BB%93/"
    >chap2 感知机模型简洁总结</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/05/12/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/chap2%20%E6%84%9F%E7%9F%A5%E6%9C%BA%E6%A8%A1%E5%9E%8B%E7%AE%80%E6%B4%81%E6%80%BB%E7%BB%93/" class="article-date">
  <time datetime="2023-05-12T12:06:20.000Z" itemprop="datePublished">2023-05-12</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="1、感知机模型"><a href="#1、感知机模型" class="headerlink" title="1、感知机模型"></a>1、感知机模型</h2><p>输入空间：$\mathcal{X} \in \mathbb{R}^n$</p>
<p>输出空间：$\mathcal{Y} = \{+1,-1\}$</p>
<p>特征空间：$\{f|f(\vec{x}) = sign(\vec{w} \cdot \vec{x} + b)\}$<br>($sign$ 为符号函数)</p>
<h2 id="2、学习策略"><a href="#2、学习策略" class="headerlink" title="2、学习策略"></a>2、学习策略</h2><p>$x_0$到超平面的距离：$\frac{1}{\Vert \vec{w} \Vert} \lvert \vec{w} \cdot \vec{x_0} + b \rvert$<br>($\Vert \vec{w} \Vert$ 是 $\vec{w}$ 的 $L_2$ 范数)</p>
<p>由于误分类点实际类别$y_i$与预测类别$f(\vec{x_i}) = sign(\vec{w} \cdot \vec{x_i} + b)$正负相反</p>
<p>因此误分类点到超平面的距离是：$-\frac{1}{\Vert \vec{w} \Vert} y_i (\vec{w} \cdot \vec{x_i} + b)$</p>
<p>为了便于求导，损失函数可以定义为：$L(\vec{w},b) = -\sum\limits_{x_i \in M} y_i (\vec{w} \cdot \vec{x_i} + b)$</p>
<h2 id="3、学习算法"><a href="#3、学习算法" class="headerlink" title="3、学习算法"></a>3、学习算法</h2><p>随机梯度下降：一次随机选取一个误分类点进行梯度下降</p>
<p>损失函数$L$ 分别对 $\vec{w}$ 和 $b$ 求梯度得：<br>$\nabla_{\vec{w}} L(\vec{w},b) = -\sum\limits_{x_i \in M} y_i \vec{x_i}$、<br>$\nabla_{b} L(\vec{w},b) = -\sum\limits_{x_i \in M} y_i$</p>
<p>参数更新方式：$\vec{w} = \vec{w} + \eta y_i x_i$、$b = b + \eta y_i$<br>($\eta \in (0,1]$ 为学习率)</p>
<p>参数一直更新，直到样本点中没有误分类点为止。</p>
<h2 id="4、对偶问题"><a href="#4、对偶问题" class="headerlink" title="4、对偶问题"></a>4、对偶问题</h2><p>由上文的学习算法可得，$\vec{w}$ 和 $b$ 是通过逐次随机选取一个误分类点更新而来</p>
<p>因此可以设 $\vec{w}$ 的每个元素和 $b$ 都为0，参数总共更新 $n$ 次；</p>
<p>最终学习到的 $\vec{w}$ 和 $b$ 可以表示为：<br>$\vec{w} = \sum\limits_{i=1}\limits^{N} \alpha_i y_i x_i$、<br>$b = \sum\limits_{i=1}\limits^{N} \alpha_i y_i$<br>($\alpha_i = n_i \eta$，其中 $n_i$ 为点i被选中用于更新的次数)</p>
<p>由第三节中提到的 $\vec{w}$ 和 $b$ 的更新方式，可以反推出 $\alpha$ 和 $b$ 的更新方式：</p>
<p>$\alpha_i = \alpha_i + \eta$、$b = b + \eta y_i$</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0%E6%96%B9%E6%B3%95/" rel="tag">统计学习方法</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-科研项目系列/粗糙度定标公式整理"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/02/19/%E7%A7%91%E7%A0%94%E9%A1%B9%E7%9B%AE%E7%B3%BB%E5%88%97/%E7%B2%97%E7%B3%99%E5%BA%A6%E5%AE%9A%E6%A0%87%E5%85%AC%E5%BC%8F%E6%95%B4%E7%90%86/"
    >粗糙度定标公式整理</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/02/19/%E7%A7%91%E7%A0%94%E9%A1%B9%E7%9B%AE%E7%B3%BB%E5%88%97/%E7%B2%97%E7%B3%99%E5%BA%A6%E5%AE%9A%E6%A0%87%E5%85%AC%E5%BC%8F%E6%95%B4%E7%90%86/" class="article-date">
  <time datetime="2023-02-19T15:09:30.000Z" itemprop="datePublished">2023-02-19</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h2 id="1-L-opt-公式形式"><a href="#1-L-opt-公式形式" class="headerlink" title="1 L_{opt}公式形式"></a>1 <script type="math/tex">L_{opt}</script>公式形式</h2><script type="math/tex; mode=display">L_{opt1}$$在低粗糙度时表现为常数，在高粗糙度时表现为指数形式：</script><p>\begin{equation}\tag{1}<br>L_{opt1}(rms,\theta,pp) = \alpha rms^{\beta}<br>\end{equation}</p>
<script type="math/tex; mode=display">

$$L_{opt2}$$在指数粗糙面和分形粗糙面时表现为$$\eqref{1}$$这类幂函数形式，
在高斯粗糙面表现为：$$L_{opt2} = \alpha rms + \beta</script><h2 id="2-L-opt1-公式"><a href="#2-L-opt1-公式" class="headerlink" title="2 L_{opt1}公式"></a>2 <script type="math/tex">L_{opt1}</script>公式</h2><h4 id="2-1-在HH极化下35-circ-的公式"><a href="#2-1-在HH极化下35-circ-的公式" class="headerlink" title="2.1 在HH极化下35^{\circ}的公式"></a>2.1 在HH极化下<script type="math/tex">35^{\circ}</script>的公式</h4><script type="math/tex; mode=display">
\begin{array}
\begin{equation}

\end{equation}</script> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%A7%91%E7%A0%94%E9%A1%B9%E7%9B%AE%E7%B3%BB%E5%88%97/" rel="tag">科研项目系列</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-pdf-test"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/02/19/pdf-test/"
    >pdf test</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/02/19/pdf-test/" class="article-date">
  <time datetime="2023-02-19T14:09:25.000Z" itemprop="datePublished">2023-02-19</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  

	<div class="row">
    <embed src="/pdf/ocean_wave_spectrum.pdf" width="100%" height="550" type="application/pdf">
	</div>



 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-latex-测试"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2023/02/19/latex-%E6%B5%8B%E8%AF%95/"
    >latex 测试</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2023/02/19/latex-%E6%B5%8B%E8%AF%95/" class="article-date">
  <time datetime="2023-02-19T13:29:56.000Z" itemprop="datePublished">2023-02-19</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <p>高斯粗糙面的均方根斜率<script type="math/tex">\sigma_{s}</script>可以表示为均方根高度<script type="math/tex">\sigma</script>和相关长度<script type="math/tex">l</script>的函数：</p>
<script type="math/tex; mode=display">\sigma_{s} = \sqrt{2}\sigma/l</script> 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
    </footer>
  </div>

    
 
    
</article>

    
    <article
  id="post-matlab编码规范学习"
  class="article article-type-post"
  itemscope
  itemprop="blogPost"
  data-scroll-reveal
>
  <div class="article-inner">
    
    <header class="article-header">
       
<h2 itemprop="name">
  <a class="article-title" href="/2022/12/16/matlab%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83%E5%AD%A6%E4%B9%A0/"
    >matlab编码规范学习</a> 
</h2>
 

      
    </header>
     
    <div class="article-meta">
      <a href="/2022/12/16/matlab%E7%BC%96%E7%A0%81%E8%A7%84%E8%8C%83%E5%AD%A6%E4%B9%A0/" class="article-date">
  <time datetime="2022-12-16T11:57:50.000Z" itemprop="datePublished">2022-12-16</time>
</a>    
    </div>
      
    <div class="article-entry" itemprop="articleBody">
       
  <h1 id="命名约定"><a href="#命名约定" class="headerlink" title="命名约定"></a>命名约定</h1><h3 id="变量"><a href="#变量" class="headerlink" title="变量"></a>变量</h3><p>变量名应该记录它们的含义或用途。<br><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wage = hourlyRate * nHours</span><br></pre></td></tr></table></figure></p>
<h4 id="从小写开始用混合大小写命名变量名"><a href="#从小写开始用混合大小写命名变量名" class="headerlink" title="从小写开始用混合大小写命名变量名"></a>从小写开始用混合大小写命名变量名</h4><p>以大写开头的名称通常是为类型或者结构体保留的。</p>
<p>很短的变量名可以是大写的，如果它们在常规用法中是大写的，并且不太可能成为复合变量名的一部分。</p>
<p>例如在特定领域，杨氏模量的E，可能会被误导为e。</p>
<p>有些程序员喜欢用下划线来分隔复合变量名的各个部分。</p>
<p>这种方式虽然易于阅读，但在其他语言中并不常用来命名变量。</p>
<p>在图形标题、标签和图例的变量名中使用下划线的另一个考虑因素是，MATLAB中的Tex解释器将把下划线转换为下标来读取，因此需要为每个文本字符串应用参数/值对进行设置，即‘Interpreter’,’none’。</p>
<h4 id="具有大作用域的变量应该具有有意义的命名，作用域小的变量可以有简短的命名"><a href="#具有大作用域的变量应该具有有意义的命名，作用域小的变量可以有简短的命名" class="headerlink" title="具有大作用域的变量应该具有有意义的命名，作用域小的变量可以有简短的命名"></a>具有大作用域的变量应该具有有意义的命名，作用域小的变量可以有简短的命名</h4><p>在实践中，大多数变量都应该具有有意义的名字。</p>
<p>在某些条件下，应保留使用简短的命名，以澄清陈述的结构或与预期的通用性相一致。</p>
 
      <!-- reward -->
      
    </div>
    

    <!-- copyright -->
    
    <footer class="article-footer">
       
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E5%B0%8F%E6%8A%80%E5%B7%A7/" rel="tag">小技巧</a></li></ul>

    </footer>
  </div>

    
 
    
</article>

    
  </article>
  

  
  <nav class="page-nav">
    
    <a class="extend prev" rel="prev" href="/">上一页</a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/3/">下一页</a>
  </nav>
  
</section>
</div>

      <footer class="footer">
  <div class="outer">
    <ul>
      <li>
        Copyrights &copy;
        2022-2024
        <i class="ri-heart-fill heart_icon"></i> CPY
      </li>
    </ul>
    <ul>
      <li>
        
      </li>
    </ul>
    <ul>
      <li>
        
        
        <span>
  <span><i class="ri-user-3-fill"></i>Visitors:<span id="busuanzi_value_site_uv"></span></span>
  <span class="division">|</span>
  <span><i class="ri-eye-fill"></i>Views:<span id="busuanzi_value_page_pv"></span></span>
</span>
        
      </li>
    </ul>
    <ul>
      
    </ul>
    <ul>
      
    </ul>
    <ul>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>    
    </main>
    <div class="float_btns">
      <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>

<div class="todark" id="todark">
  <i class="ri-moon-line"></i>
</div>

    </div>
    <aside class="sidebar on">
      <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="My Blog"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/friends">友链</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2019/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
    </aside>
    <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    <div class="reward-item">
      <img class="reward-img" src="/images/alipay.jpg">
      <span class="reward-type">支付宝</span>
    </div>
    
    
    <div class="reward-item">
      <img class="reward-img" src="/images/wechat.jpg">
      <span class="reward-type">微信</span>
    </div>
    
  </div>
</div>
    
<script src="/js/jquery-3.6.0.min.js"></script>
 
<script src="/js/lazyload.min.js"></script>

<!-- Tocbot -->

<script src="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.js"></script>
<link
  rel="stylesheet"
  href="https://cdn.staticfile.org/jquery-modal/0.9.2/jquery.modal.min.css"
/>
<script src="https://cdn.staticfile.org/justifiedGallery/3.8.1/js/jquery.justifiedGallery.min.js"></script>

<script src="/dist/main.js"></script>

<!-- ImageViewer -->
 <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.staticfile.org/photoswipe/4.1.3/default-skin/default-skin.min.css">
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe.min.js"></script>
<script src="https://cdn.staticfile.org/photoswipe/4.1.3/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script> 
<!-- MathJax -->
 <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
      tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
  });

  MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
      }
  });
</script>

<script src="https://cdn.staticfile.org/mathjax/2.7.7/MathJax.js"></script>
<script src="https://cdn.staticfile.org/mathjax/2.7.7/config/TeX-AMS-MML_HTMLorMML-full.js"></script>
<script>
  var ayerConfig = {
    mathjax: true,
  };
</script>

<!-- Katex -->
 
    
        <link rel="stylesheet" href="https://cdn.staticfile.org/KaTeX/0.15.1/katex.min.css">
        <script src="https://cdn.staticfile.org/KaTeX/0.15.1/katex.min.js"></script>
        <script src="https://cdn.staticfile.org/KaTeX/0.15.1/contrib/auto-render.min.js"></script>
        
    
 
<!-- busuanzi  -->
 
<script src="/js/busuanzi-2.3.pure.min.js"></script>
 
<!-- ClickLove -->

<!-- ClickBoom1 -->

<!-- ClickBoom2 -->

<!-- CodeCopy -->
 
<link rel="stylesheet" href="/css/clipboard.css">
 <script src="https://cdn.staticfile.org/clipboard.js/2.0.10/clipboard.min.js"></script>
<script>
  function wait(callback, seconds) {
    var timelag = null;
    timelag = window.setTimeout(callback, seconds);
  }
  !function (e, t, a) {
    var initCopyCode = function(){
      var copyHtml = '';
      copyHtml += '<button class="btn-copy" data-clipboard-snippet="">';
      copyHtml += '<i class="ri-file-copy-2-line"></i><span>COPY</span>';
      copyHtml += '</button>';
      $(".highlight .code pre").before(copyHtml);
      $(".article pre code").before(copyHtml);
      var clipboard = new ClipboardJS('.btn-copy', {
        target: function(trigger) {
          return trigger.nextElementSibling;
        }
      });
      clipboard.on('success', function(e) {
        let $btn = $(e.trigger);
        $btn.addClass('copied');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-checkbox-circle-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPIED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-checkbox-circle-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
      clipboard.on('error', function(e) {
        e.clearSelection();
        let $btn = $(e.trigger);
        $btn.addClass('copy-failed');
        let $icon = $($btn.find('i'));
        $icon.removeClass('ri-file-copy-2-line');
        $icon.addClass('ri-time-line');
        let $span = $($btn.find('span'));
        $span[0].innerText = 'COPY FAILED';
        
        wait(function () { // 等待两秒钟后恢复
          $icon.removeClass('ri-time-line');
          $icon.addClass('ri-file-copy-2-line');
          $span[0].innerText = 'COPY';
        }, 2000);
      });
    }
    initCopyCode();
  }(window, document);
</script>
 
<!-- CanvasBackground -->

<script>
  if (window.mermaid) {
    mermaid.initialize({ theme: "forest" });
  }
</script>


    
    

  </div>
</body>

</html>